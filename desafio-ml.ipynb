{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafío - Machine Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import ParameterGrid, RepeatedKFold, GridSearchCV, train_test_split\n",
    "from warnings import WarningMessage\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, scale\n",
    "from sklearn.svm import SVC\n",
    "import multiprocessing\n",
    "\n",
    "WarningMessage = False\n",
    "plt.rcParams[\"figure.dpi\"] = 150\n",
    "plt.rcParams[\"font.family\"] = \"Fira Sans Extra Condensed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de entrenamiento\n",
    "data_web = pd.read_csv(\"data/usuarios_win_mac_lin_train.csv\")\n",
    "data_web.describe()\n",
    "\n",
    "# Datos de validacion\n",
    "data_validation = pd.read_csv(\"data/data_validation_without_class.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = data_web.hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data_web.corr()\n",
    "sns.heatmap(corr, annot = True, square = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data_web, hue=\"clase\", height = 2, palette = 'colorblind')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revision de outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de componentes principales (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# media de cada variable\n",
    "print('Media de las variables')\n",
    "print(data_web.mean(axis=0))\n",
    "# Varianza\n",
    "print('Varianza de las variables')\n",
    "print(data_web.var(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que estandarizar los datos para que variables con alta media y varianza no dominen el PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento modelo PCA con escalado de los datos\n",
    "# ==============================================================================\n",
    "pca_pipe = make_pipeline(StandardScaler(), PCA()) # Estandar Scaler estandariza, PCA obtiene componentes\n",
    "pca_pipe.fit(data_web)\n",
    "\n",
    "# Se extrae el modelo entrenado del pipeline\n",
    "modelo_pca = pca_pipe.named_steps['pca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_pca.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convierto los componentes del modelo para analizar sus combinaciones lineales e importancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se combierte el array a dataframe para añadir nombres a los ejes.\n",
    "pd.DataFrame(\n",
    "    data    = modelo_pca.components_,\n",
    "    columns = data_web.columns,\n",
    "    index   = ['PC1', 'PC2', 'PC3', 'PC4', 'PC5']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisis visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap componentes\n",
    "# ==============================================================================\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(4, 2))\n",
    "componentes = modelo_pca.components_\n",
    "plt.imshow(componentes.T, cmap='viridis', aspect='auto')\n",
    "plt.yticks(range(len(data_web.columns)), data_web.columns)\n",
    "plt.xticks(range(len(data_web.columns)), np.arange(modelo_pca.n_components_) + 1)\n",
    "plt.grid(False)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A partir de los autovalores, calculamos la \n",
    "# varianza explicada (% representatividad)\n",
    "\n",
    "var_exp = modelo_pca.explained_variance_ratio_ *100  # ratio de varianza explicada por 100 (para que quede en %)\n",
    "cum_var_exp = np.cumsum(var_exp) # varianza acumulada por componente \n",
    "\n",
    "n_components = len(modelo_pca.components_)\n",
    "# Representamos en un diagrama de barras la varianza explicada por cada autovalor, y la acumulada\n",
    "# with plt.style.context('seaborn-pastel'):\n",
    "plt.figure(figsize=(4, 3))\n",
    "\n",
    "plt.bar(range(n_components), var_exp, alpha=0.5, align='center',\n",
    "        label='Varianza individual explicada', color='g')\n",
    "plt.step(range(n_components), cum_var_exp, where='mid', linestyle='--', label='Varianza explicada acumulada')\n",
    "plt.ylabel('Ratio de Varianza Explicada')\n",
    "plt.xlabel('Componentes Principales')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "## Pendiente -> anotar labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_web[['duracion', 'paginas', 'acciones', 'valor']]  # Features\n",
    "y=data_web['clase']  # Labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos dict con pesos de cada clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pesos = {\n",
    "    0:0.5116279,\n",
    "    1:0.2558135,\n",
    "    2:0.23255813\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo 1 -  DecisionTree\n",
    "\n",
    "Clasificador DecisionTree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con menos componentes\n",
    "X=data_web[['acciones','valor']]  # Features\n",
    "y=data_web['clase']  # Labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, stratify=y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Árbol de desición\n",
    "modelo_tree=DecisionTreeClassifier(max_depth = 3, random_state = 1, )\n",
    "# fit\n",
    "modelo_tree.fit(X_train,y_train)\n",
    "\n",
    "y_pred=modelo_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_tree.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fn = ['duracion', 'paginas', 'acciones', 'valor']\n",
    "fn = ['duracion', 'valor']\n",
    "cn = [\"0\", \"1\", \"2\"]\n",
    "\n",
    "plt.figure(figsize = (5,4))\n",
    "plot_tree(modelo_tree, feature_names = fn, class_names = cn, filled = True)\n",
    "plt.tight_layout(h_pad=0.5, w_pad=0.5)\n",
    "\n",
    "# Si el gini tiende a cero, el error tiende a cero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = modelo_tree.predict(X = X_test)\n",
    "print(metrics.classification_report(y_true = y_test,\n",
    "y_pred = predicciones\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo 2 - Random Forest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=6, n_jobs=-1, random_state=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_rf =  RandomForestClassifier(\n",
    "            n_estimators = 100,\n",
    "            n_jobs       = -1,\n",
    "            max_depth= 6,\n",
    "            random_state = 1\n",
    "         )\n",
    "      \n",
    "modelo_rf.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6744186046511628\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "# ==============================================================================\n",
    "y_pred = modelo_rf.predict(X_test.values)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.77      0.71        22\n",
      "           1       0.50      0.20      0.29        10\n",
      "           2       0.77      0.91      0.83        11\n",
      "\n",
      "    accuracy                           0.67        43\n",
      "   macro avg       0.64      0.63      0.61        43\n",
      "weighted avg       0.65      0.67      0.64        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicciones = modelo_rf.predict(X = X_test.values)\n",
    "print(metrics.classification_report(y_true = y_test,\n",
    "y_pred = predicciones\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: {'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'n_estimators': 100} ✓\n",
      "Modelo: {'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'n_estimators': 150} ✓\n",
      "Modelo: {'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'n_estimators': 100} ✓\n",
      "Modelo: {'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'n_estimators': 150} ✓\n",
      "Modelo: {'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'n_estimators': 100} ✓\n",
      "Modelo: {'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'n_estimators': 150} ✓\n",
      "Modelo: {'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'n_estimators': 100} ✓\n",
      "Modelo: {'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'n_estimators': 150} ✓\n",
      "Modelo: {'criterion': 'gini', 'max_depth': 6, 'max_features': 1, 'n_estimators': 100} ✓\n",
      "Modelo: {'criterion': 'gini', 'max_depth': 6, 'max_features': 1, 'n_estimators': 150} ✓\n",
      "Modelo: {'criterion': 'gini', 'max_depth': 6, 'max_features': 2, 'n_estimators': 100} ✓\n",
      "Modelo: {'criterion': 'gini', 'max_depth': 6, 'max_features': 2, 'n_estimators': 150} ✓\n",
      "Modelo: {'criterion': 'gini', 'max_depth': 10, 'max_features': 1, 'n_estimators': 100} ✓\n",
      "Modelo: {'criterion': 'gini', 'max_depth': 10, 'max_features': 1, 'n_estimators': 150} ✓\n",
      "Modelo: {'criterion': 'gini', 'max_depth': 10, 'max_features': 2, 'n_estimators': 100} ✓\n",
      "Modelo: {'criterion': 'gini', 'max_depth': 10, 'max_features': 2, 'n_estimators': 150} ✓\n",
      "Modelo: {'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'n_estimators': 100} ✓\n",
      "Modelo: {'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'n_estimators': 150} ✓\n",
      "Modelo: {'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'n_estimators': 100} ✓\n",
      "Modelo: {'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'n_estimators': 150} ✓\n",
      "Modelo: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'n_estimators': 100} ✓\n",
      "Modelo: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'n_estimators': 150} ✓\n",
      "Modelo: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'n_estimators': 100} ✓\n",
      "Modelo: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'n_estimators': 150} ✓\n",
      "Modelo: {'criterion': 'entropy', 'max_depth': 6, 'max_features': 1, 'n_estimators': 100} ✓\n",
      "Modelo: {'criterion': 'entropy', 'max_depth': 6, 'max_features': 1, 'n_estimators': 150} ✓\n",
      "Modelo: {'criterion': 'entropy', 'max_depth': 6, 'max_features': 2, 'n_estimators': 100} ✓\n",
      "Modelo: {'criterion': 'entropy', 'max_depth': 6, 'max_features': 2, 'n_estimators': 150} ✓\n",
      "Modelo: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 1, 'n_estimators': 100} ✓\n",
      "Modelo: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 1, 'n_estimators': 150} ✓\n",
      "Modelo: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 2, 'n_estimators': 100} ✓\n",
      "Modelo: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 2, 'n_estimators': 150} ✓\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oob_accuracy</th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.732283</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.724409</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.716535</td>\n",
       "      <td>gini</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.708661</td>\n",
       "      <td>gini</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    oob_accuracy criterion  max_depth  max_features  n_estimators\n",
       "16      0.732283   entropy        NaN             1           100\n",
       "28      0.724409   entropy       10.0             1           100\n",
       "12      0.716535      gini       10.0             1           100\n",
       "8       0.708661      gini        6.0             1           100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid de hiperparámetros evaluados\n",
    "# ==============================================================================\n",
    "param_grid = ParameterGrid(\n",
    "                {'n_estimators': [100,150],\n",
    "                 'max_features': [1,2],\n",
    "                 'max_depth'   : [None,3, 6, 10],\n",
    "                 'criterion'   : ['gini', 'entropy']\n",
    "                }\n",
    "            )\n",
    "\n",
    "# Loop para ajustar un modelo con cada combinación de hiperparámetros\n",
    "# ==============================================================================\n",
    "resultados = {'params': [], 'oob_accuracy': []}\n",
    "\n",
    "for params in param_grid:\n",
    "    \n",
    "    modelo = RandomForestClassifier(\n",
    "                oob_score    = True,\n",
    "                n_jobs       = -1,\n",
    "                random_state = 123,\n",
    "                ** params\n",
    "             )\n",
    "    \n",
    "    modelo.fit(X_train.values, y_train)\n",
    "    \n",
    "    resultados['params'].append(params)\n",
    "    resultados['oob_accuracy'].append(modelo.oob_score_)\n",
    "    print(f\"Modelo: {params} \\u2713\")\n",
    "\n",
    "# Resultados\n",
    "# ==============================================================================\n",
    "resultados = pd.DataFrame(resultados)\n",
    "resultados = pd.concat([resultados, resultados['params'].apply(pd.Series)], axis=1)\n",
    "resultados = resultados.sort_values('oob_accuracy', ascending=False)\n",
    "resultados = resultados.drop(columns = 'params')\n",
    "resultados.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error de test del modelo final\n",
    "# ==============================================================================\n",
    "modelo_rf =  RandomForestClassifier(\n",
    "            n_estimators = 150,\n",
    "            n_jobs       = -1,\n",
    "            max_depth= 6,\n",
    "            random_state = 1,\n",
    "            max_features = 2,\n",
    "            criterion='entropy'\n",
    "         )\n",
    "\n",
    "modelo_rf.fit(X_train.values, y_train)        \n",
    "\n",
    "predicciones = modelo_rf.predict(X = X_test.values)\n",
    "mat_confusion = metrics.confusion_matrix(\n",
    "                    y_true    = y_test,\n",
    "                    y_pred    = predicciones\n",
    "                )\n",
    "\n",
    "accuracy = metrics.accuracy_score(\n",
    "            y_true    = y_test,\n",
    "            y_pred    = predicciones,\n",
    "            normalize = True\n",
    "           )\n",
    "\n",
    "print(\"Matriz de confusión\")\n",
    "print(\"-------------------\")\n",
    "print(mat_confusion)\n",
    "print(\"\")\n",
    "print(f\"El accuracy de test es: {100 * accuracy} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo 3 - RandomForest con PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('pca', PCA(n_components=4)),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(class_weight={0: 0.5116279,\n",
       "                                                      1: 0.2558135,\n",
       "                                                      2: 0.23255813},\n",
       "                                        random_state=1))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamiento modelo PCA con escalado de los datos\n",
    "# ==============================================================================\n",
    "# N components = 4 por el análisis anterior\n",
    "pca_pipe = make_pipeline(StandardScaler(), PCA(n_components=4), RandomForestClassifier(random_state=1, class_weight=pesos) ) # Estandar Scaler estandariza, PCA obtiene componentes\n",
    "pca_pipe.fit(X_train.values, y_train.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviso  metricas del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80        22\n",
      "           1       0.75      0.60      0.67        10\n",
      "           2       0.83      0.91      0.87        11\n",
      "\n",
      "    accuracy                           0.79        43\n",
      "   macro avg       0.79      0.78      0.78        43\n",
      "weighted avg       0.79      0.79      0.79        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicciones = pca_pipe.predict(X = X_test.values)\n",
    "print(metrics.classification_report(y_true = y_test,\n",
    "y_pred = predicciones\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'standardscaler', 'pca', 'randomforestclassifier', 'standardscaler__copy', 'standardscaler__with_mean', 'standardscaler__with_std', 'pca__copy', 'pca__iterated_power', 'pca__n_components', 'pca__random_state', 'pca__svd_solver', 'pca__tol', 'pca__whiten', 'randomforestclassifier__bootstrap', 'randomforestclassifier__ccp_alpha', 'randomforestclassifier__class_weight', 'randomforestclassifier__criterion', 'randomforestclassifier__max_depth', 'randomforestclassifier__max_features', 'randomforestclassifier__max_leaf_nodes', 'randomforestclassifier__max_samples', 'randomforestclassifier__min_impurity_decrease', 'randomforestclassifier__min_samples_leaf', 'randomforestclassifier__min_samples_split', 'randomforestclassifier__min_weight_fraction_leaf', 'randomforestclassifier__n_estimators', 'randomforestclassifier__n_jobs', 'randomforestclassifier__oob_score', 'randomforestclassifier__random_state', 'randomforestclassifier__verbose', 'randomforestclassifier__warm_start'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_pipe.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {\n",
    "            \"randomforestclassifier__criterion\": ['gini', 'entropy'],\n",
    "            \"randomforestclassifier__n_estimators\":[100,150,200,500,1000],\n",
    "            'randomforestclassifier__criterion': ['gini', 'entropy'],\n",
    "            'randomforestclassifier__max_features':   [1,2,3,4],\n",
    "            \n",
    "\n",
    "              }\n",
    "\n",
    "estimator = GridSearchCV(pca_pipe,\n",
    "                         param_dict,\n",
    "                         verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=100; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=100; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=100; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=100; total time=   0.1s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=100; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=150; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=150; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=150; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=200; total time=   0.4s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=500; total time=   0.8s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=500; total time=   0.8s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=500; total time=   0.9s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=500; total time=   0.9s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=500; total time=   1.1s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=1000; total time=   1.7s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=1000; total time=   2.3s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=1000; total time=   1.7s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=1000; total time=   1.6s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=1000; total time=   1.5s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=100; total time=   0.1s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=100; total time=   0.1s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=100; total time=   0.1s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=100; total time=   0.1s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=100; total time=   0.1s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=500; total time=   0.7s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=500; total time=   0.7s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=500; total time=   0.7s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=500; total time=   0.7s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=500; total time=   0.7s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=1000; total time=   1.5s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=1000; total time=   1.9s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=1000; total time=   1.7s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=1000; total time=   1.6s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=1000; total time=   1.6s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=100; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=100; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=100; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=100; total time=   0.1s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=100; total time=   0.1s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=200; total time=   0.4s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=200; total time=   0.4s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=500; total time=   0.9s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=500; total time=   0.8s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=500; total time=   0.9s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=500; total time=   1.0s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=500; total time=   0.9s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=1000; total time=   1.7s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=1000; total time=   1.7s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=1000; total time=   1.8s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=1000; total time=   2.7s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=1000; total time=   1.9s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=100; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=100; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=100; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=100; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=100; total time=   0.1s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=150; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=150; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=500; total time=   0.8s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=500; total time=   0.8s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=500; total time=   0.8s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=500; total time=   0.8s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=500; total time=   0.8s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=1000; total time=   1.6s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=1000; total time=   1.8s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=1000; total time=   1.9s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=1000; total time=   1.7s\n",
      "[CV] END randomforestclassifier__criterion=gini, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=1000; total time=   1.8s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=100; total time=   0.1s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=100; total time=   0.1s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=100; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=100; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=100; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=150; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=500; total time=   0.8s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=500; total time=   0.8s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=500; total time=   0.8s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=500; total time=   0.7s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=500; total time=   0.8s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=1000; total time=   1.5s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=1000; total time=   1.6s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=1000; total time=   1.6s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=1000; total time=   1.5s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=1, randomforestclassifier__n_estimators=1000; total time=   1.6s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=100; total time=   0.1s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=100; total time=   0.1s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=100; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=100; total time=   0.1s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=100; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=150; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=500; total time=   0.8s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=500; total time=   0.8s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=500; total time=   0.8s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=500; total time=   0.8s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=500; total time=   0.8s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=1000; total time=   1.6s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=1000; total time=   1.6s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=1000; total time=   1.6s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=1000; total time=   1.6s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=2, randomforestclassifier__n_estimators=1000; total time=   1.8s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=100; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=100; total time=   0.1s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=100; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=100; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=100; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=150; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=150; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=500; total time=   0.8s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=500; total time=   0.9s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=500; total time=   1.0s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=500; total time=   0.8s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=500; total time=   1.0s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=1000; total time=   1.7s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=1000; total time=   1.7s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=1000; total time=   1.7s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=1000; total time=   1.6s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=3, randomforestclassifier__n_estimators=1000; total time=   1.6s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=100; total time=   0.1s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=100; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=100; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=100; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=100; total time=   0.1s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=150; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=150; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=150; total time=   0.2s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=200; total time=   0.4s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=200; total time=   0.3s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=500; total time=   0.8s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=500; total time=   0.8s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=500; total time=   0.8s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=500; total time=   0.8s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=500; total time=   0.9s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=1000; total time=   1.7s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=1000; total time=   2.6s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=1000; total time=   2.6s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=1000; total time=   2.6s\n",
      "[CV] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_features=4, randomforestclassifier__n_estimators=1000; total time=   2.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('pca', PCA(n_components=4)),\n",
       "                                       ('randomforestclassifier',\n",
       "                                        RandomForestClassifier(class_weight={0: 0.5116279,\n",
       "                                                                             1: 0.2558135,\n",
       "                                                                             2: 0.23255813},\n",
       "                                                               random_state=1))]),\n",
       "             param_grid={'randomforestclassifier__criterion': ['gini',\n",
       "                                                               'entropy'],\n",
       "                         'randomforestclassifier__max_features': [1, 2, 3, 4],\n",
       "                         'randomforestclassifier__n_estimators': [100, 150, 200,\n",
       "                                                                  500, 1000]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_final = estimator.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('pca', PCA(n_components=4)),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(class_weight={0: 0.5116279,\n",
       "                                                      1: 0.2558135,\n",
       "                                                      2: 0.23255813},\n",
       "                                        max_features=4, n_estimators=500,\n",
       "                                        random_state=1))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  test del modelo final\n",
    "# ==============================================================================\n",
    "predicciones = modelo_final.predict(X = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80        22\n",
      "           1       0.75      0.60      0.67        10\n",
      "           2       0.83      0.91      0.87        11\n",
      "\n",
      "    accuracy                           0.79        43\n",
      "   macro avg       0.79      0.78      0.78        43\n",
      "weighted avg       0.79      0.79      0.79        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    metrics.classification_report(\n",
    "        y_true = y_test,\n",
    "        y_pred = predicciones\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADA Boost\n",
    "\n",
    "https://machinelearningmastery.com/adaboost-ensemble-in-python/  \n",
    "https://www.cienciadedatos.net/documentos/py09_gradient_boosting_python.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('pca', PCA(n_components=4)),\n",
       "                ('adaboostclassifier',\n",
       "                 AdaBoostClassifier(base_estimator=RandomForestClassifier(max_features=4,\n",
       "                                                                          n_estimators=500,\n",
       "                                                                          random_state=1),\n",
       "                                    learning_rate=0.1, random_state=1))])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rfc = RandomForestClassifier(\n",
    "                                        max_features=4, n_estimators=500,\n",
    "                                        random_state=1)\n",
    "\n",
    "adb_pipe = make_pipeline(StandardScaler(), PCA(n_components=4), AdaBoostClassifier(random_state=1,base_estimator=Rfc, learning_rate=0.1) ) # Estandar Scaler estandariza, PCA obtiene componentes\n",
    "adb_pipe.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'standardscaler', 'pca', 'adaboostclassifier', 'standardscaler__copy', 'standardscaler__with_mean', 'standardscaler__with_std', 'pca__copy', 'pca__iterated_power', 'pca__n_components', 'pca__random_state', 'pca__svd_solver', 'pca__tol', 'pca__whiten', 'adaboostclassifier__algorithm', 'adaboostclassifier__base_estimator', 'adaboostclassifier__learning_rate', 'adaboostclassifier__n_estimators', 'adaboostclassifier__random_state'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adb_pipe.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabian.ortega\\.conda\\envs\\ml\\lib\\site-packages\\sklearn\\base.py:434: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80        22\n",
      "           1       0.75      0.60      0.67        10\n",
      "           2       0.83      0.91      0.87        11\n",
      "\n",
      "    accuracy                           0.79        43\n",
      "   macro avg       0.79      0.78      0.78        43\n",
      "weighted avg       0.79      0.79      0.79        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicciones = adb_pipe.predict(X = X_test)\n",
    "print(metrics.classification_report(y_true = y_test,\n",
    "y_pred = predicciones\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 0, 0, 0, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 1, 0, 2, 0, 1, 2,\n",
       "       0, 0, 2, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 2, 0, 0, 2, 0, 1, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "357dca2462728d9971563f46dc7d519403b886495a584fedb12a448da962c743"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ml': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
